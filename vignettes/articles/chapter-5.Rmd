---
title: "Chapter 5: Treating time more flexibly"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
ggplot2::theme_set(ggplot2::theme_bw())
ggplot2::theme_update(
  panel.grid.major = ggplot2::element_blank(),
  panel.grid.minor = ggplot2::element_blank()
)
```

```{r setup}
library(alda)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(ggplot2)
library(lme4)
library(broom.mixed)
library(modelbased)
library(modelsummary)
library(gt)
```

## 5.1 Variably Spaced Measurement Occasions

In Section 5.1 Singer and Willet (2003) demonstrate how you can fit the multilevel model for change for data with **variably spaced measurement occasions** using a subset of data from the Children of the National Longitudinal Study of Youth (US Bureau of Labor and Statistics), which measured changes in the reading subtest of the Peabody Individual Achievement Test (PIAT) in a sample of 89 African-American children across three waves around the ages of 6, 8, and 10.

For this example we use the `reading_scores` data set, a person-period data frame with 267 rows and 5 columns:

- `id`: Child ID.
- `wave`: Wave of measurement.
- `age_group`: Expected age on each measurement occasion.
- `age`: Age in years at time of measurement.
- `reading_score`: Reading score on the reading subtest of the Peabody Individual Achievement Test (PIAT).

```{r}
# Table 5.1, page 141:
reading_scores
```

Note that the structure of the `reading_scores` data is identical to the person-period data sets shown in previous chapters, except that it has three time-indicator variables:

- The values of `wave` reflect the study's design; they are time-structured across children, but have little substantive meaning.
- The values of `age_group` reflect the child's expected age on each measurement occasion; they are time-structured across children and have substantive meaning.
- The values of `age` reflect the child's actual age on each measurement occasion; they are variably spaced across children and have substantive meaning.

This demonstrates a distinctive feature of **time-unstructured** data sets---the possibility to have multiple representations of time. Thus, from the perspective of the `age_group` variable, the `reading_scores` data appears to be time-structured:

```{r}
select(reading_scores, id, age_group, reading_score)
```

Whereas from the perspective of the `age` variable, the `reading_scores` data appears to be variably spaced:

```{r}
select(reading_scores, id, age, reading_score)
```

However, as Singer and Willett (2003) discuss, the specification, estimation, and interpretation of the multilevel model for change proceeds in the exact same way regardless of which temporal representation we use; thus, it is generally preferable to use the most accurate unstructured temporal representation rather forcing the data into a time-structured design.

Here we will fit an unconditional growth model using both the structured and unstructured temporal representations to demonstrate why the latter is generally preferable. As usual, we begin by inspecting empirical growth plots to help select the functional form for the level-1 submodel.

```{r}
# Figure 5.1, page 143:
reading_scores |>
  filter(id %in% c(4, 27, 31, 33, 41, 49, 69, 77, 87)) |>
  pivot_longer(
    starts_with("age"), names_to = "time_indicator", values_to = "age"
  ) |>
  ggplot(aes(x = age, y = reading_score, colour = time_indicator)) +
    geom_point() +
    stat_smooth(method = "lm", se = FALSE, linewidth = .5) +
    scale_x_continuous(breaks = 5:12) +
    scale_color_brewer(palette = "Dark2") +
    coord_cartesian(xlim = c(5, 12), ylim = c(0, 80)) +
    facet_wrap(vars(id), labeller = label_both)
```

A linear change individual growth model seems most parsimonious for both temporal representations. Following Singer and Willett (2003), we will centre both `age_group` and `age` on age 6.5 (the average child’s age at wave 1) so that the parameters of both models have identical interpretations, and label time in each model with a generic `time` variable.

```{r}
reading_scores_fits <- map(
  list(age_group = "age_group", age = "age"),
  \(.time) {
    lmer(
      reading_score ~ I(time - 6.5) + (1 + I(time - 6.5) | id),
      data = mutate(reading_scores, time = .data[[.time]]),
      REML = FALSE
    )
  }
)

options(modelsummary_get = "all")

# Table 5.2, page 145:
reading_scores_fits |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)",
      "I(time - 6.5)",
      "var__Observation",
      "var__(Intercept)",
      "var__I(time - 6.5)"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 8:10) |>
  tab_row_group(label = "Variance Components", rows = 5:7) |>
  tab_row_group(label = "Fixed Effects", rows = 1:4) |>
  cols_hide(effect)
```

Comparing these models, we see that the `age` model fits the data better than the `age_group` model---with less unexplained variation in initial status and rates of change, and smaller AIC and BIC statistics.  

## 5.2 Varying Numbers of Measurement Occasions

In Section 5.2 Singer and Willet (2003) demonstrate how you can fit the multilevel model for change for data with **varying numbers of measurement occasions** (i.e., unbalanced data) using a subset of data from the National Longitudinal Study of Youth tracking the labour market experiences of male high school dropouts (Murnane, Boudett, & Willett, 1999).

For this example we use the `dropout_wages` data set, a person-period data frame with 6402 rows and 9 columns:

- `id`: Participant ID.
- `log_wages`: Natural logarithm of wages.
- `experience`: Labour force experience in years, tracked from dropouts' first day of work.
- `ged`: Binary indicator for whether the dropout obtained a GED.
- `postsecondary_education`: Binary indicator for whether the dropout obtained post-secondary education.
- `black`: Binary indicator for whether the dropout is black.
- `hispanic`: Binary indicator for whether the dropout is hispanic.
- `highest_grade`: Highest grade completed.
- `unemployment_rate`: Unemployment rate in the local geographic area.

```{r}
dropout_wages
```

In the `dropout_wages` data, the number of measurement occasions varies widely across individuals, from 1 to 13 waves.

```{r}
dropout_wages |>
  group_by(id) |>
  summarise(waves = n()) |>
  count(waves, name = "count")
```

Indeed, examining the data from a subset of individuals, we can see that the `dropout_wages` data varies in both the number *and* spacing of measurement occasions.

```{r}
# Table 5.3, page 147:
dropout_wages |>
  filter(id %in% c(206, 332, 1028)) |>
  select(id, experience, log_wages, black, highest_grade, unemployment_rate)
```

Yet, as Singer and Willet (2003) discuss, a major advantage of the multilevel model for change is that it can easily fit to unbalanced data like this---as long as the person-period data set includes enough people with enough waves of data for the model converge, the analyses can proceed as usual. 

Here we will fit three models to the `dropout_wages` data: an unconditional growth model (Model A), and two models that include predictors for race and the highest grade completed (Models B and C).

```{r}
# Fit models ------------------------------------------------------------------
dropout_wages_fit_A <- lmer(
  log_wages ~ experience + (1 + experience | id),
  data = dropout_wages,
  REML = FALSE
)

dropout_wages_fit_B <- update(
  dropout_wages_fit_A,
  . ~ . + experience * I(highest_grade - 9) + experience * black
)

# The model fails to converge with the default optimizer (although the estimates
# are fine). Changing the optimizer achieves convergence.
dropout_wages_fit_C <- update(
  dropout_wages_fit_B,
  . ~ . - experience:I(highest_grade - 9) - black,
  control = lmerControl(optimizer = "bobyqa")
)

dropout_wages_fits <- list(
  `Model A` = dropout_wages_fit_A,
  `Model B` = dropout_wages_fit_B,
  `Model C` = dropout_wages_fit_C
)

# Make table ------------------------------------------------------------------

# Table 5.4, page 149:
dropout_wages_fits |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)",
      "I(highest_grade - 9)",
      "black",
      "experience",
      "experience:I(highest_grade - 9)",
      "experience:black",
      "var__Observation",
      "var__(Intercept)",
      "var__experience"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 15:18) |>
  tab_row_group(label = "Variance Components", rows = 13:15) |>
  tab_row_group(label = "Fixed Effects", rows = 1:12) |>
  cols_hide(effect)
```

Likewise, even for data with varying numbers of measurement occasions, prototypical change trajectories can be derived from the model as usual. 

```{r}
prototypical_dropout_wages <- dropout_wages_fit_C |>
  estimate_prediction(
    data = crossing(
      experience = c(0, 12),
      highest_grade = c(0, 3) + 9,
      black = c(FALSE, TRUE)
    )
  ) |>
  rename(log_wages = Predicted) |>
  mutate(highest_grade = factor(highest_grade)) |>
  as_tibble()

# Figure 5.2, page 150:
ggplot(prototypical_dropout_wages, aes(x = experience, y = log_wages)) +
  geom_line(aes(colour = highest_grade, linetype =  black)) +
  scale_x_continuous(breaks = seq(0, 12, by = 2)) +
  scale_color_brewer(palette = "Dark2") +
  scale_linetype_manual(values = c(2, 1)) +
  coord_cartesian(ylim = c(1.6, 2.4))
```

### 5.2.2 Practical Problems That May Arise When Analyzing Unbalanced Data Sets

The multilevel model may fail to converge or be unable to estimate one or more variance components for data sets that are severely unbalanced, or if too few people have enough waves of data. In Section 5.2.2 Singer and Willet (2003) discuss two strategies for addressing these problems:

- **Removing boundary constraints**, where the software is permitted to obtain negative variance components.
- **Fixing rates of change**, where the model is simplified by removing the varying slope change.

For this example we a subset of the `dropout_wages` data purposefully constructed to be severely unbalanced.

```{r}
dropout_wages_subset
```

First we will refit Model C to the `dropout_wages_subset` data. Note that the estimated variance component for `experience` is practically zero and the model summary has the following message at the bottom: "boundary (singular) fit: see help('isSingular')". 

```{r}
dropout_wages_fit_A_subset <- update(
  dropout_wages_fit_C,
  data = dropout_wages_subset
)

summary(dropout_wages_fit_A_subset)
```

The first strategy Singer and Willett (2003) suggest is to remove the boundary constraints of the software, however, the **lme4** package does not support the removal of boundary constraints to allow for negative variance components, so this strategy cannot be replicated (Model B).

The second strategy is to simplify the model by fixing rates of change, which we do by removing the varying slope for experience. Here the model fits without issue.

```{r}
dropout_wages_fit_C_subset <- update(
  dropout_wages_fit_A_subset,
  . ~ . - (1 + experience | id) + (1 | id)
)

summary(dropout_wages_fit_C_subset)
```

Comparing Models A and C, note that their deviance statistics are identical, and that the AIC and BIC statistics are smaller in Model C, suggesting that: (1) Model C is an improvement over Model A; and (2) we cannot effectively model systematic interindividual differences in rates of change with this data set.

```{r}
dropout_wages_fits_subset <- list(
  `Model A` = dropout_wages_fit_A_subset,
  `Model C` = dropout_wages_fit_C_subset
)

# Table 5.5, page 154:
dropout_wages_fits_subset |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)",
      "I(highest_grade - 9)",
      "black",
      "experience",
      "experience:I(highest_grade - 9)",
      "experience:black",
      "var__Observation",
      "var__(Intercept)",
      "var__experience"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 12:14) |>
  tab_row_group(label = "Variance Components", rows = 9:11) |>
  tab_row_group(label = "Fixed Effects", rows = 1:8) |>
  cols_hide(effect)
```

## 5.3 Time-Varying Predictors

In Section 5.3 Singer and Willett (2003) demonstrate how to fit the multilevel model for change for data with **time-varying predictors** using a subset of data from Ginexi, Howe, and Caplan (2000), who measured changes in depressive symptoms after job loss in a sample of 254 recently unemployed men and women. Interviews were conducted in three waves at around 1, 5, and 12 months after job loss.

For this example we use the `depression_unemployment` data set, a person-period data frame with 674 rows and 5 columns:

- `id`: Participant ID.
- `interview`: Time of interview.
`months`: Months since job loss.
- `depression`: Total score on the Center for Epidemiologic Studies' Depression (CES-D) scale (Radloff, 1977).
- `unemployed`: Binary indicator for whether the participant was unemployed at time of interview. Note that all participants were unemployed at the first interview, and changes in unemployment status were gathered during the second and third interviews. 

```{r}
depression_unemployment
```

In the `depression_unemployment` data, both the number and spacing of measurement occasions varies across individuals.

A total of 193 participants (76%) had three interviews, 34 participants (13.4%) had two interviews, and 27 participants (10.6%) had only one interview.

```{r}
depression_unemployment |>
  group_by(id) |>
  summarise(waves = n()) |>
  count(waves, name = "count") |>
  mutate(proportion = count / sum(count))
```

The average time between job loss and the first interview was 27.6 days (SD = 10.7; range = 2-61), 151 days for the second interview (SD = 18.3; range = 111-220), and 359 days for the third interview (SD = 19.1; range = 319-458).

```{r}
depression_unemployment |>
  group_by(interview) |>
  mutate(days = months * 30.4167) |>
  summarise(
    mean = mean(days),
    sd = sd(days),
    min = min(days),
    max = max(days)
  )
```

Additionally, examining the data for a subset of individuals, we can see that the `unemployed` variable is a time-varying predictor with several unique patterns of change across participants. <!-- (e.g., patterns 1-1-1, 1-0-1, 1-0-0; etc.) -->

```{r}
# Table 5.6, page 161:
filter(depression_unemployment, id %in% c(7589, 55697, 67641, 65441, 53782))
```

Considering only participants with complete data, 78 were unemployed at every interview (pattern 1-1-1), 55 were always employed after the first interview (pattern 1-0-0), 41 were still unemployed at the second interview but employed at the third (pattern 1-1-0), and 19 were employed at the second interview but unemployed at the third (pattern 1-0-1).

```{r}
unemployed_patterns <- depression_unemployment |>
  group_by(id) |>
  filter(n() == 3) |>
  summarise(unemployed_pattern = paste(unemployed, collapse = "-")) |>
  count(unemployed_pattern, name = "count")

unemployed_patterns
```

As with the previous examples, no special strategies are needed to fit the multilevel model for change with time-varying predictors. However, as Singer and Willett (2003) discuss, the inclusion of time-varying predictors in a model implies the existence of multiple **continuous** and **discontinuous** change trajectories---one for each possible pattern of the time-varying predictors.

Here we will fit four models to the `depression_unemployment` data: an unconditional growth model (Model A), a model that includes the main effect of a time-varying predictor (Model B), a model that includes an interaction effect with a time-varying predictor (Model C), and a model that allows a time-varying predictor to have both fixed and random effects (Model D).

Note that for Model D, Singer and Willett (2003) fit this model using SAS, which does not report any issues with the model given the data; however, other programs (R, MPlus, SPSS, STATA) all have convergence/singularity problems and it is not possible to get results that match the textbook. Each of these programs react differently to this situation, but it is reasonable to conclude the problem is not with the software, but with this model being too complex, given the data.

```{r}
# Fit models ------------------------------------------------------------------
depression_unemployment_fit_A <- lmer(
  depression ~ months + (1 + months | id),
  data = depression_unemployment,
  REML = FALSE
)

# The model fails to converge with the default optimizer (although the
# estimates are fine). Changing the optimizer achieves convergence.
depression_unemployment_fit_B <- update(
  depression_unemployment_fit_A,
  . ~ . + unemployed,
  control = lmerControl(optimizer = "bobyqa")
)

depression_unemployment_fit_C <- update(
  depression_unemployment_fit_B,
  . ~ . + months:unemployed
)

# The number of observations is less than the number of random effects levels
# for each term, which makes the random effects variances (probably)
# unidentifiable in this model and throws an error. In order to fit the model
# we need to ignore this check.
depression_unemployment_fit_D <- lmer(
  depression ~ 
    unemployed + unemployed:months + (1 + unemployed + months:unemployed | id),
  data = depression_unemployment,
  REML = FALSE,
  control = lmerControl(check.nobs.vs.nRE = "ignore")
)

depression_unemployment_fits <- list(
  `Model A` = depression_unemployment_fit_A,
  `Model B` = depression_unemployment_fit_B,
  `Model C` = depression_unemployment_fit_C,
  `Model D` = depression_unemployment_fit_D
)

# Make table ------------------------------------------------------------------

# Table 5.7, page 163:
depression_unemployment_fits |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)" = "(Intercept)",
      "months" = "months",
      "black" = "black",
      "unemployed" = "unemployed",
      "months:unemployed" = "months:unemployed",
      "unemployed:months" = "months:unemployed",
      "var__Observation" = "var__Observation",
      "var__(Intercept)" = "var__(Intercept)",
      "var__months" = "var__months",
      "var__unemployed" = "var__unemployed",
      "var__unemployed:months" = "var__unemployed:months"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 14:16) |>
  tab_row_group(label = "Variance Components", rows = 9:13) |>
  tab_row_group(label = "Fixed Effects", rows = 1:8) |>
  cols_hide(effect)
```

<!-- TODO:
p. 229, 262

Moreover, 
>When you add a time-varying predictor, as either a main effect or an interaction, you change the meaning of the individual growth parameters because: • The intercept parameter, π0i, now refers to the value of the outcome when all level-1 predictors, not only TIME but also the time-varying predictor, are zero. • The slope parameter, π1i, is now a conditional rate of change, controlling for the effects of the time-varying predictor. Altering the population quantity that each parameter represents alters the meaning of the associated level-2 variance component. Hence, it makes no sense to compare the magnitude of these variance components across successive models. This means that you must rely on changes in the time-varying predictors fixed effects, and associated goodness-of-fit statistics, when deciding (p.171) whether to retain a timevarying predictor in your model.
-->

### Plotting discontinuous change trajectories

Unlike previous examples, the addition of a time-varying predictor in the model implies that a given change trajectory may be composed of either **one continuous segment** or **multiple discontinuous segments**. Because of this, new strategies are required to construct a data set for prototypical individuals and plot their fitted change trajectories, where each segment has its own start and end times and predictions. This data set can be in either a wide or long format, however: For wide formats, each segment must be plotted using the `geom_segment()` function from the **ggplot2** package; whereas for long formats, each segment must have its own grouping ID, but can otherwise be plotted using the `geom_line()` function as usual. We demonstrate both formats here by constructing prototypical change trajectories for Model B. 

A convenient way to construct a data set for prototypical individuals in wide format is with the `reframe()` function from the **dplyr** package, which works similarly to the `summarise()` function, but can return an arbitrary number of rows per group. Here we use it to (1) expand each `unemployed_pattern` string into a numeric vector using the `str_extract_all()` function from the **stringr** package; and (2) add start and stop times for each segment. After this prediction proceeds as usual, except that we use dplyr's `across()` function to avoid writing the same `predict()` code.

```{r}
prototypical_depression_B <- unemployed_patterns |>
  select(-count) |>
  group_by(unemployed_pattern) |>
  reframe(
    unemployed = str_extract_all(unemployed_pattern, "[:digit:]", simplify = TRUE),
    unemployed = as.numeric(unemployed),
    months_start = c(0, 5, 10),
    months_end = c(5, 10, 15),
  ) |>
  mutate(
    across(
      starts_with("months"),
      \(.time) {
        predict(
          depression_unemployment_fit_B,
          tibble(unemployed, months = .time),
          re.form = NA
        )
      },
      .names = "depression_{.col}"
    ),
    unemployed_pattern = factor(
      unemployed_pattern, levels = c("1-1-1", "1-0-0", "1-1-0", "1-0-1")
    )
  ) |>
  rename_with(
    \(.x) str_remove(.x, "months_"), .cols = starts_with("depression")
  )

prototypical_depression_B
```

Although we will plot the prototypical trajectories using the wide format data, note here that a convenient way to create a grouping ID for long format data is with the `consecutive_id()` function from the dplyr package, which generates a unique identifier that increments every time a variable changes. The resulting variable can then be passed to ggplot2's `group` aesthetic to ensure the correct cases are connected together.

```{r}
prototypical_depression_B |>
  pivot_longer(
    cols = c(starts_with("months"), starts_with("depression")),
    names_to = c(".value"),
    names_pattern = "(^.*(?=_))"
  ) |>
  group_by(unemployed_pattern) |>
  mutate(cid = consecutive_id(unemployed), .after = unemployed_pattern)
```

Now we can plot the four trajectories.

```{r}
# Figure 5.3:
ggplot(prototypical_depression_B, aes(x = months_start, y = depression_start)) +
  geom_segment(aes(xend = months_end, yend = depression_end)) +
  coord_cartesian(ylim = c(5, 20)) +
  facet_wrap(vars(unemployed_pattern), labeller = label_both) +
  labs(x = "months", y = "depression")
```

An alternative strategy for plotting discontinuous change trajectories suggested by Singer and Willett (2003) is to represent the wide variety of transition times using just two continuous trajectories that encompass the most extreme contrasts possible: Here, someone who is consistently unemployed, and someone who is consistently employed. With this approach, prototypical change trajectories can be predicted and plotted using the same strategies we have used for models with time-invariant predictors, while conveying the same (or more) information as the set of discontinuous trajectories above.

We demonstrate this alternative strategy for Models B, C, and D. Because of the `depression_unemployment` study's design, we start the fitted trajectory for a consistently employed individual at 3.5 months---the earliest time a participant could have their second interview.

```{r}
prototypical_depression <- depression_unemployment_fits[-1] |>
  map(
    \(.fit) {
      .fit |>
        estimate_prediction(
          data = tibble(months = c(0, 14, 3.5, 14), unemployed = c(1, 1, 0, 0))
        ) |>
        rename(depression = Predicted) |>
        mutate(unemployed = as.logical(unemployed)) |>
        as_tibble()
    }
  ) |>
  list_rbind(names_to = "model")

# Figure 5.4, page 167:
ggplot(prototypical_depression, aes(x = months, y = depression)) +
  geom_line(aes(colour = unemployed)) +
  scale_x_continuous(breaks = seq(0, 14, by = 2)) +
  scale_color_brewer(palette = "Dark2") +
  coord_cartesian(xlim = c(0, 14), ylim = c(5, 20)) +
  facet_wrap(vars(model))
```

When examining plots like these, Singer and Willett (2003) suggest thinking of the two extreme trajectories as an envelope representing the complete set of prototypical individuals implied by each model:

- Because all participants were unemployed at the first interview (by design), each individual starts on the unemployed trajectory.
- For the second interview---regardless of the transition time---those who become employed move to the employed trajectory, and those who don't stay on the unemployed trajectory.
- For the third interview---regardless of the transition time---those who become unemployed again move back to the unemployed trajectory, and those who don't stay on the employed trajectory.

### 5.3.3 Recentring time-varying predictors

In Section 5.3.3 Singer and Willett (2003) return to the `dropout_wages` data to discuss three strategies for centring time-varying predictors:

- **Constant centring**: Centre around a single substantively meaningful constant for all observations.
- **Within-person centring**: Decompose the time-varying predictor into two constituent predictors where, for each individual, the first predictor is their *within-person mean*; and the second predictor is each measurement occasion's *deviation from their within-person mean*.
- **Time-one centring**: Decompose the time-varying predictor into two constituent predictors where, for each individual, the first predictor is the value of their *first measurement occasion*; and the second predictor is each measurement occasion's *deviation from the first measurement occasion*.

We demonstrate each of these strategies by updating Model C, `dropout_wages_fit_C`, to include the main effect of the time-varying predictor `unemployment_rate`, fitting a model that uses constant centring (Model A2), within-person centring (Model B2), and time-one centring (Model C2).

```{r}
# Fit models ------------------------------------------------------------------
dropout_wages_fit_A2 <- update(
  dropout_wages_fit_C,
  . ~ . + I(unemployment_rate - 7)
)

dropout_wages_fit_B2 <- update(
  dropout_wages_fit_C,
  . ~ . + unemployment_rate_mean + unemployment_rate_dev,
  data = mutate(
    dropout_wages,
    unemployment_rate_mean = mean(unemployment_rate),
    unemployment_rate_dev = unemployment_rate - unemployment_rate_mean,
    .by = id
  )
)

dropout_wages_fit_C2 <- update(
  dropout_wages_fit_C,
  . ~ . + unemployment_rate_first + unemployment_rate_dev,
  data = mutate(
    dropout_wages,
    unemployment_rate_first = first(unemployment_rate),
    unemployment_rate_dev = unemployment_rate - unemployment_rate_first,
    .by = id
  )
)

dropout_wages_fits_2 <- list(
  `Model A2` = dropout_wages_fit_A2,
  `Model B2` = dropout_wages_fit_B2,
  `Model C2` = dropout_wages_fit_C2
)

# Make table ------------------------------------------------------------------

# Table 5.8:
dropout_wages_fits_2 |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)" = "(Intercept)",
      "I(highest_grade - 9)" = "I(highest_grade - 9)",
      "I(unemployment_rate - 7)" = "unemployment_rate",
      "unemployment_rate_mean" = "unemployment_rate",
      "unemployment_rate_first" = "unemployment_rate",
      "unemployment_rate_dev" = "unemployment_rate_dev",
      "black" = "black",
      "experience" = "experience",
      "experience:I(highest_grade - 9)" = "experience:I(highest_grade - 9)",
      "experience:black" = "experience:black",
      "var__Observation" = "var__Observation",
      "var__(Intercept)" = "var__(Intercept)",
      "var__experience" = "var__experience"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    fmt = 4,
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 16:18) |>
  tab_row_group(label = "Variance Components", rows = 13:15) |>
  tab_row_group(label = "Fixed Effects", rows = 1:12) |>
  cols_hide(effect)
```

## 5.4 Recentring the effect of time

In Section 5.4 Singer and Willett (2003) discuss strategies for centring time-indicator variables using a subset of data from Tomarken, Shelton, Elkins, and Anderson (1997), who measured the relation between changes in positive mood and supplemental antidepressant medication over the course of a week in a sample of 73 men and women already receiving nonpharmacological therapy for depression.

For this example we use the `antidepressants` data set, a person-period data frame with 1242 rows and 8 columns:

- `id`: Participant ID.
- `wave`: Wave of measurement.
- `day`: Day of measurement.
- `reading`: Time of day a reading was taken.
<!--
- `time_of_day`: Time of day a reading was taken, expressed numerically (0 for morning readings; 0.33 for afternoon readings; 0.67 for evening readings).
- `time`: Time of measurement expressed as a combination of `day` and `time_of_day`.
-->
- `positive_mood`: Positive mood score.
- `treatment`: Treatment condition (placebo pills = 0, antidepressant pills = 1).

```{r}
antidepressants
```

Note that the `antidepressants` data has three time-indicator variables, each providing a different representation of time:

- The values of `wave` reflect the study's design, but have little substantive meaning due to the conceptual difficulty of dividing one week into 21 components.
- The values of `day` reflect the study's design in a meaningful way, but fail to distinguish between morning, afternoon, and evening readings.
- The values of `reading` also reflect the study's design in a meaningful way---capturing the time of day each reading was taken---but fail to distinguish between days, and are difficult to analyze due to being a character vector.

To facilitate model fitting, we can create new time-indicator variables that are more meaningful and easier to analyze. Here we create two new time-indicator variables:

- `time_of_day`: Time of day a reading was taken, expressed numerically (0 for morning readings; 0.33 for afternoon readings; 0.67 for evening readings).
- `time`: Time of measurement expressed as a combination of `day` and `time_of_day`.

```{r}
antidepressants <- antidepressants |>
  mutate(
    time_of_day = case_when(
      reading == "8 AM" ~ 0,
      reading == "3 PM" ~ 1/3,
      reading == "10 PM" ~ 2/3
    ),
    time = day + time_of_day,
    .after = reading
  )

antidepressants
```

The advantage of the `time` variable is that it captures both aspects of time in the `antidepressants` data in a single variable, making it is easy to centre on different time points in the study. Following Singer and Willett (2003), here we centre `time` on three different points in the study:

- `time`: centred on initial status.
- `time_3.33`: centred on the study's midpoint.
- `time_6.67`: centred on the study's final wave.

```{r}
# Table 5.9, page 182:
antidepressants |>
  select(-c(id, positive_mood, treatment)) |>
  mutate(time_3.33 = time - 3.33, time_6.67 = time - 6.67)
```

Here we will fit three models to the `antidepressants` data to demonstrate how centring time affects parameter estimates and interpretation: a model with time centred on initial status (Model A), a model with time centred on the study's midpoint (Model B), a model with time centred on the study's final wave (Model C).

```{r}
# Fit models ------------------------------------------------------------------
antidepressants_fit_A <- lmer(
  positive_mood ~ treatment * time + (1 + time | id),
  data = antidepressants,
  REML = FALSE
)

antidepressants_fit_B <- update(
  antidepressants_fit_A,
  data = mutate(antidepressants, time = time - 3.33),
  control = lmerControl(optimizer = "bobyqa")
)

antidepressants_fit_C <- update(
  antidepressants_fit_A,
  data = mutate(antidepressants, time = time - 6.67)
)

antidepressants_fits <- list(
  `Model A` = antidepressants_fit_A,
  `Model B` = antidepressants_fit_B,
  `Model C` = antidepressants_fit_C
)

# Make table ------------------------------------------------------------------

# Table 5.10, page 184:
antidepressants_fits |>
  modelsummary(
    shape = term + effect + statistic ~ model,
    scales = c("vcov", NA),
    coef_map = c(
      "(Intercept)",
      "treatment",
      "time",
      "treatment:time",
      "var__Observation",
      "var__(Intercept)",
      "var__time",
      "cov__(Intercept).time"
    ),
    gof_map = tibble(
      raw = c("deviance", "AIC", "BIC"),
      clean = c("Deviance", "AIC", "BIC"),
      fmt = 1
    ),
    output = "gt"
  ) |>
  tab_row_group(label = "Goodness-of-Fit", rows = 13:15) |>
  tab_row_group(label = "Variance Components", rows = 9:12) |>
  tab_row_group(label = "Fixed Effects", rows = 1:8) |>
  cols_hide(effect)
```

Notice that the parameters related to the slope are identical between Models A, B, and C, but the those related to the intercept are different. As Singer and Willett (2003) explain, this is because centring a time-indicator variable changes the location of the fitted trajectory's anchors around a given point in time.

We can visualize this anchoring effect by plotting prototypical change trajectories for the models fit to the `antidepressants` data: As the dashed vertical lines highlight, centring a time-indicator variable changes the location of the focal comparison between the control and treatment groups in the model, causing the resultant estimates to describe the trajectories behaviours at that specific point in time.

Note that because Models A, B, and C are structurally identical, it does not matter which model is used here to make predictions---they all have the same prototypical change trajectories.

```{r}
protoypical_mood <- antidepressants_fit_A |>
  estimate_prediction(
    data = tibble(
      treatment = c(0, 0, 0, 1, 1, 1),
      time = c(0, 3.33, 6.67, 0, 3.33, 6.67)
    )
  ) |>
  rename(positive_mood = Predicted) |>
  mutate(treatment = as.logical(treatment))
  
# Figure 5.5, page 185:
ggplot(protoypical_mood, aes(x = time, y = positive_mood)) +
    geom_line(aes(colour = treatment)) +
    geom_line(aes(group = time), linetype = 2) +
    scale_x_continuous(breaks = seq(0, 7, by = 1)) +
    scale_color_brewer(palette = "Dark2") +
    coord_cartesian(ylim = c(140, 190))
```
